{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa27677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:12:22.249886Z",
     "iopub.status.busy": "2025-05-12T18:12:22.249490Z",
     "iopub.status.idle": "2025-05-12T18:12:22.263146Z",
     "shell.execute_reply": "2025-05-12T18:12:22.261322Z",
     "shell.execute_reply.started": "2025-05-12T18:12:22.249860Z"
    },
    "papermill": {
     "duration": 0.0071,
     "end_time": "2025-05-13T17:31:19.805833",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.798733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> What to diffuse? The basics! </b></div>\n",
    "\n",
    "\n",
    "|![Probabilistic Graphical Model Diagram](https://hojonathanho.github.io/diffusion/assets/img/pgm_diagram_xarrow.png \"Probabilistic Graphical Model Diagram\")\n",
    "|:--:|\n",
    "|Diagram from [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd05205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T18:12:22.249886Z",
     "iopub.status.busy": "2025-05-12T18:12:22.249490Z",
     "iopub.status.idle": "2025-05-12T18:12:22.263146Z",
     "shell.execute_reply": "2025-05-12T18:12:22.261322Z",
     "shell.execute_reply.started": "2025-05-12T18:12:22.249860Z"
    },
    "papermill": {
     "duration": 0.005714,
     "end_time": "2025-05-13T17:31:19.817685",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.811971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"padding: 20px; border-color: #a61d2f; border-radius: 0px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #1279D4; width: 75%; margin: 0 auto; background-color: #1279D4;\">\n",
    "    <p style=\"font-size: 20px; font-family: 'Georgia'; line-height: 1.5em;\">\n",
    "    “A diffusion model is a parameterised Markov Chain trained using variational inference to produce samples matching the data after finite time.” - <a href=\"https://arxiv.org/pdf/2006.11239\" style=\"color: #0000EE; text-decoration: underline;\">Denoising Diffusion Probabilistic Models</a>\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "This is a direct quote from the paper, that introduced diffusion models, but how do you make one and what is the intuition behind these diffusion models? That is what I want to explain in this post.\n",
    "It consist out of the following parts;\n",
    "\n",
    "- What can we do with diffusion models and why do they exists?\n",
    "- What are the underlying assumptions we make about this diffusion process?\n",
    "- How do we convert these underlying assumptions to a loss function that we can use to train a model.\n",
    "- How do we go from loss function to a trainable model and train it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46cb23b",
   "metadata": {
    "papermill": {
     "duration": 0.006735,
     "end_time": "2025-05-13T17:31:19.830300",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.823565",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> What can we do with diffusion models? </b></div>\n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/00-SampleSpace.png?raw=true)\n",
    "|:--:|\n",
    "\n",
    "At its core, diffusion models are generative models used to generate new samples of a distribution. The idea behind generative modelling is to derive for a given dataset $\\mathcal{D}$ of observations $x^{(1)}, \\cdots x^{(N)}$ to learn or derive the underlying distribution from which the data is generated. Thus derive $x \\sim p_{data}$. Which enables us to sample from this distribution and thus generate more samples, which is the goal of diffusion models. \n",
    "\n",
    "The sample space for images is $x \\in \\mathbb{R}^{H\\times W}$,  is incredibly big, while most of this space is occupied mostly be noisy samples. As I attempted to visualise in the picture above.\n",
    "\n",
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Generating samples </b></div>\n",
    "As mentioned before, we want to sample previously unseen examples, thus we need a mapping that produces a sample inside the space $x \\in \\R^{H\\times W}$. A Generative Adversarial Network (GAN), is a technique that produces such a mapping (the generator). This generator takes as input noise and outputs an image \n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/01-GAN.png?raw=true)\n",
    "|:--:|\n",
    "\n",
    "$$\n",
    "g_\\theta(x_{noise}) = x_{img}\n",
    "$$\n",
    "\n",
    "GANs however have two major problems;\n",
    "\n",
    "- Mode collapse, this meant that the generator only learned to predict one specific sample. Thus it collapses the whole space $\\{x | p_{true}(x) \\geq 0.9\n",
    "\\}$ into one sample.\n",
    "- Unstable training, due to the adversarial nature of a GAN, you have to train a generator and discriminator together. When the complexity of the discriminator and the generator are not balanced, the two models will just stop learning from each other and nothing sensible happens.\n",
    "\n",
    "Diffusion models solve these problems by modeling the underlying data distribution in a sequential way. \n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/02-Diffusion.png?raw=true)\n",
    "|:--:|\n",
    "\n",
    "In this way the training objective becomes more stable, since the whole problem is split into many smaller problems. And it doesn’t require the training of a discriminator, since the it just learns to denoise samples.\n",
    "\n",
    "A different way to look at diffusion models that I found very useful is that of the perspective of score models, that basically says that diffusion models try to a score function $s(x)$, which is the gradient of the log likelihood and points, for each point $x \\in \\mathbb{R}^{H\\times W}$to the direction that makes your sample more likely.\n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/03-ScoreFunction.png?raw=true)\n",
    "|:--:|\n",
    "$$\n",
    "s(x) \\approx \\nabla_x \\log{p(x)} \\Big(= \\epsilon_\\theta(x, t) \\Big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb64fdf6",
   "metadata": {
    "papermill": {
     "duration": 0.005418,
     "end_time": "2025-05-13T17:31:19.841290",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.835872",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - Forward process </b></div>\n",
    "This part explain the math behind diffusion models and how to get a loss function we will employ to train a model. Most of the math comes from the blogpost [What are Diffusion Models?](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/) and from the paper [link](https://arxiv.org/pdf/2006.11239). I have rewritten the equations and added the schematics in way that it makes more sense to me, and I hope it makes it helps you as well.\n",
    "\n",
    "As just mentioned, diffusion models make the assumption that samples are sequentially constructed from noise. This means that there is a sequence of hidden latent variables that starts with $x_T \\sim \\mathcal{N}(0, \\sigma^2)$ where gradually information is added (or de-noised), until there is a clean sample without noise $x_0$. \n",
    "\n",
    "Before I can explain how to generate data, I need to start with the forward process, the process where data is destroyed. \n",
    "\n",
    "This is defined by the approximate posterior. \n",
    "\n",
    "$$\n",
    "q(x_{1:T}|x_0) = \\prod_{t=1}^T q(x_t|x_{t-1})\n",
    "$$\n",
    "\n",
    "With the transition probabilities.\n",
    "\n",
    "$$\n",
    "q(x_t|x_{t-1}) = \\mathcal{N}(x_t|\\sqrt{1-\\beta_t} x_{t-1}, \\beta_tI)\n",
    "$$\n",
    "\n",
    "Where the sequence $\\beta_0, \\cdots, \\beta_{T}$ is the variance schedule that controls how fast information is destroyed in the process. Using the [reparameterization trick](https://lilianweng.github.io/posts/2018-08-12-vae/#reparameterization-trick) we can expess $x_t$\n",
    "\n",
    "$$\n",
    "x_{t} = \\sqrt{1-\\beta_{t-1}} \\cdot x_{t-1} + \\sqrt{\\beta_{t-1}} \\cdot \\epsilon_{t-1}\n",
    "$$\n",
    "\n",
    "Were\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\mathcal{N}(0, I)\n",
    "$$\n",
    "\n",
    "The reason why this setup is so convenient is that we can use this property to derive a tractable form for $x_t$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_{t} &= \\sqrt{1-\\beta_{t-1}} \\cdot x_{t-1} + \\sqrt{\\beta_{t-1}} \\cdot \\epsilon_{t-1} \\\\\n",
    "x_{t} &= \\sqrt{1-\\beta_{t-1}} \\cdot (\\sqrt{1-\\beta_{t-2}} \\cdot x_{t-2} + \\sqrt{\\beta_{t-2}} \\cdot \\epsilon_{t-2}) + \\sqrt{\\beta_{t-1}} \\cdot \\epsilon_{t-1} \\\\\n",
    "x_{t} &= \\sqrt{1-\\beta_{t-1}}  \\sqrt{1-\\beta_{t-2}} \\cdot x_{t-2} + \\sqrt{1-\\beta_{t-1}}\\sqrt{\\beta_{t-2}} \\cdot \\epsilon_{t-2} +  \\sqrt{\\beta_{t-1}} \\cdot \\epsilon_{t-1} \\\\\n",
    "\\vdots \\\\\n",
    "x_{t} &= \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{(1-\\bar{\\alpha}_t)}\\cdot\\epsilon_{combined}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    " Gaussian distribution to derive a tractable form;\n",
    "\n",
    "$$\n",
    "q(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1-\\bar{\\alpha}_t)I)\n",
    "$$\n",
    "\n",
    "Where we use the identities\n",
    "\n",
    "$$\n",
    "\\alpha_t = 1-\\beta_t \\\\\n",
    "\\bar{\\alpha}=\\prod_{s=1}^t\\alpha_t\n",
    "$$\n",
    "\n",
    "This simply means that we can sample $x_t$ for arbitrary $t$ using the reparameterization trick. \n",
    "\n",
    "Before we are finished with the forward process, I want to define one more probability, the forward process posteriors;\n",
    "\n",
    "$$\n",
    "q(x_{t-1}|x_t ,x_0)  = \\mathcal{N}(x_{t-1};\\hat{\\mu}_t(x_t, x_0), \\hat{\\beta}_t)\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\hat{\\mu}_t(x_t, x_0) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1-\\bar\\alpha_t}x_0 + \\frac{\\sqrt{\\alpha_t}(1-\\bar\\alpha_{t-1})}{{1-\\bar\\alpha}_t}x_t\n",
    "$$\n",
    "\n",
    "And\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}_t = \\frac{1-\\bar{\\alpha}_{t-1}}{1-\\bar\\alpha_t}\\beta_t\n",
    "$$\n",
    "\n",
    "The reason why this guy is important will be clear at the end of the blogpost. Now we know, how we can derive, given a sample $x \\in \\mathcal{D}$, a latent $x_t$ for an arbitrary $t$.\n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/05-Forward.png?raw=true)\n",
    "|:--:|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f48a0",
   "metadata": {
    "papermill": {
     "duration": 0.005515,
     "end_time": "2025-05-13T17:31:19.852384",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.846869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - Reverse process </b></div>\n",
    "\n",
    "So, now we have defined the forward process, lets look at what we actually want to learn, namely the reverse process. This process is defined by \n",
    "\n",
    "$$\n",
    "p_\\theta(x_0) = \\int p_\\theta(x_0, x_1, \\cdots, x_{T-1}) d{x_{1:T}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_\\theta(x_0, \\cdots, x_{T-1}) = p_\\theta(x_0)\\prod_{t=1}^Tp_\\theta(x_{t-1}|x_t)\n",
    "$$\n",
    "\n",
    "In this reverse process the transitions are assumed to be \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p_{\\theta}(x_{t-1}|x_t)  &= \\mathcal{N}\\Big(x_{t-1};\\mu_\\theta(x_t, t), \\hat{\\beta}_t \\mathbf{I}\\Big ) \n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Where $\\mu_\\theta(x_t, t)$ is the function distribution we want to learn! This function we can rewrite to;\n",
    "\n",
    "$$\n",
    "\\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t - \\frac{\\beta_t}{\\sqrt{1-\\hat\\alpha_t}}\\epsilon_\\theta(x_t, t) \\Big)\n",
    "$$\n",
    "\n",
    "When we have this function $p_\\theta(x_{t-1}|x_t)$, we can use the resample trick to sequentially reconstruct samples from noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0460dac",
   "metadata": {
    "papermill": {
     "duration": 0.005596,
     "end_time": "2025-05-13T17:31:19.863762",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.858166",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - From definition to loss function </b></div>\n",
    "\n",
    "\n",
    "So we just defined the diffusion process as a Markov chain, now we need to come up with a loss which we can use to optimise the parameters of our model $\\theta$.\n",
    "\n",
    "Starting with the joint distribution can be done by minimising the log-likelihood for the model;\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&=-\\log \\big( p_{\\theta}(x) \\big) = -\\log \\big( \\int p_\\theta(x_{0:T})dx_{1:T} \\big) \\\\\n",
    "&=-\\log \\big( \\int p_\\theta(x_{0:T})\\cdot \\frac{q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)} dx_{1:T} \\big) \\\\\n",
    "&= -\\log \\big(\\mathbb{E}_q\\Big[ \\frac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\Big] \\big)\\leq -\\mathbb{E}_q\\Big[\\log \\big( \\frac{p_\\theta(x_{0:T})}{q(x_{1:T}|x_0)} \\Big) \\Big] \\\\\n",
    "&=-\\mathbb{E}_q\\Big[-\\log p(x_T) - \\sum_{t\\geq 1} \\log \\{\\frac{p_\\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\\} \\Big]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The problem with this is that we are now comparing $p_\\theta(x_{t-1}|x_t)$  with $q(x_t|x_{t-1})$. It would be way nicer if we could compare for each timestep $t$, the approximate reverse forward process with the posterior forward process, $q(x_{t-1}|x_t, x_0)$ (which we just derived). This can be done by rewriting if we substitute;\n",
    "\n",
    "$$\n",
    "q(x_t|x_{t-1}) = \\frac{q(x_t|x_0)}{q(x_{t-1}|x_0)} \\cdot q(x_{t-1}|x_t, x_0)\\\\\n",
    "$$\n",
    "\n",
    "To obtain\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&=-\\mathbb{E}_q\\Big[-\\log p(x_T) - \\sum_{t\\geq 1} \\log \\{\\frac{p_\\theta(x_{t-1} |x_t)}{q(x_t|x_{t-1})}\\} \\Big] \\\\\n",
    "&=-\\mathbb{E}_q\\Big[-\\log p(x_T) - \\sum_{t>1} \\log \\{\\frac{p_\\theta(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\\} -\\log \\big\\{ \\frac{p_\\theta(x_0|x_1)}{q(x_1|x_0)}\\big\\}\\Big] \\\\\n",
    "&=-\\mathbb{E}_q\\Big[-\\log p(x_T) - \\sum_{t>1} \\log \\Bigg\\{\\frac{p_\\theta(x_{t-1}|x_t}{q(x_{t-1}|x_t, x_0)}\\cdot\\frac{q(x_{t-1}|x_0)} {q(x_t|x_0)}\\Bigg\\} -\\log \\big\\{ \\frac{p_\\theta(x_0|x_1)}{q(x_1|x_0)}\\big\\}\\Big] \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Rewritting \n",
    "\n",
    "$$\n",
    "-\\sum_{t>1}\\log\\Bigg\\{\\frac{q(x_{t-1}|x_0)} {q(x_t|x_0)}\\Bigg\\} = \\log q(x_1|x_0) - \\log q(x_T|x_0)\n",
    "$$\n",
    "\n",
    "And substitution gives us\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&=-\\mathbb{E}_q\\Big[-\\log p(x_T) - \\sum_{t>1} \\log \\Bigg\\{\\frac{p_\\theta(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\cdot\\frac{q(x_{t-1}|x_0)} {q(x_t|x_0)}\\Bigg\\} -\\log \\big\\{ \\frac{p_\\theta(x_0|x_1)}{q(x_1|x_0)}\\big\\}\\Big] \\\\\n",
    "&=-\\mathbb{E}_q\\Big[ - \\log \\Big\\{\\frac{p(x_T)}{q(x_T|x_0)}\\Big\\} - \\sum_{t>1} \\log \\Bigg\\{\\frac{p_\\theta(x_{t-1}|x_t)}{q(x_{t-1}|x_t, x_0)}\\Bigg\\} - \\log\\big\\{p_\\theta(x_0|x_1)\\big\\}\\Big]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This means that if we want parameters $\\theta$ that minimises the log-likelihood, we need to make sure that these parameters minimises a lower bound which consist out of the following terms;\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}_q\\Big[&D_{KL}\\big[q(x_1|x_0)||p(x_1|x_0)\\big] \\\\\n",
    "&+ \\sum_{t>1}D_{KL}\\big[q(x_{t-1}|x_t, x_0) || p_\\theta(x_{t-1}|x_t) \\big]\n",
    "\\\\ &-\\log p_\\theta(x_0|x_1)\n",
    "\\Big]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Which we can decompose into;\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&L_T = D_{KL}\\big[q(x_T|x_0)||p(x_T)\\big] \\\\\n",
    "&L_{t-1} = \\sum_{t>1}D_{KL}\\big[q(x_{t-1}|x_t, x_0) || p_\\theta(x_{t-1}|x_t) \\big]\\\\\n",
    "&L_0 = - \\log p_\\theta(x_0|x_1)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "This basically says that we can optimise the lower bound by only looking at $L_{t-1}$, because $L_T$  is constant during training and can be ignored. \n",
    "\n",
    "Because both $p_\\theta$ and $q$ are both Gaussians, the divergence becomes;\n",
    "\n",
    "$$\n",
    "L_{t-1} = \\mathbb{E}_q\\Big[\\frac{1}{2\\sigma^2_t}||\\hat\\mu(x_t, x_0) - \\mu_\\theta(x_t, t)||^2\\Big]\n",
    "$$\n",
    "\n",
    "This means that the most straightforward way to implement the reverse diffusion process is to simply predict $\\mu(x_t, x_0)$. This is the first way to implement a diffusion model. \n",
    "\n",
    "The second way is rewriting to;\n",
    "\n",
    "$$\n",
    "\\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t - \\frac{\\beta_t}{\\sqrt{1-\\hat\\alpha_t}}\\epsilon_\\theta(x_t, t) \\Big)\n",
    "$$\n",
    "\n",
    "The authors of the paper found this more convenient.\n",
    "Which leads to an even simpler version of the lower bound\n",
    "$$\n",
    "L_{simple}(\\theta) = \\mathbb{E}\\Big[||\\epsilon - \\epsilon_\\theta(\\sqrt{\\hat\\alpha_t}x_0 +\\sqrt{1-\\hat\\alpha_t}\\epsilon, t)||^2\\Big]\n",
    "$$\n",
    "\n",
    "In this way we don’t directly predict, given a variable $x_t$ what was the previous $x_{t-1}$, but we predict, given $x_t$, what the noise $\\epsilon_{\\theta}(x_t, t)$ at that given timestep. Intuitively, we predict which direction we have to move to make our sample less noisy.\n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/06-DiffusionLoss.png?raw=true)\n",
    "|:--:|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2312fc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:05:03.459235Z",
     "iopub.status.busy": "2025-05-12T23:05:03.458927Z",
     "iopub.status.idle": "2025-05-12T23:05:03.469568Z",
     "shell.execute_reply": "2025-05-12T23:05:03.468228Z",
     "shell.execute_reply.started": "2025-05-12T23:05:03.459209Z"
    },
    "papermill": {
     "duration": 0.005449,
     "end_time": "2025-05-13T17:31:19.874983",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.869534",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> UNET architecture </b></div>\n",
    "|![Probabilistic Graphical Model Diagram](https://github.com/JPABotermans/KaggleNotebooks/blob/main/Images/DiffusionModels/06-Unet.png?raw=true)\n",
    "|:--:|\n",
    "|UNET diagram from [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)|\n",
    "\n",
    "\n",
    "So now we know what we want, namely $\\epsilon_\\theta(x, t)$, a model that takes as input a distorted sample $x_t$ and outputs the noise $\\epsilon$ that was added for timestep $t$ and we know that we want to apply a mse loss on this model. So for this we use an UNET, just like the authors of the original diffusion models, and we use a convolution with a shift scale operation to condition this on the timestep. \n",
    "\n",
    "\n",
    "This UNET consist out of a few building blocks which I will explain from small to big, starting with a basic convolutional block;\n",
    "\n",
    "```python\n",
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 kernel_size: int = 3, \n",
    "                 stride: int = 1, \n",
    "                 padding: int = 1,\n",
    "                 bias: bool = False,\n",
    "                 nrm: bool = True,\n",
    "                 act: bool = True,\n",
    "                ) -> None:\n",
    "        \"\"\"A basic convolutional block, convolution, activation and normalization. Uses Groupnorm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "            padding=padding, \n",
    "            bias=bias)\n",
    "        \n",
    "        self.nrm_fn = torch.nn.GroupNorm(num_groups=8, num_channels=out_channels) if nrm else torch.nn.Identity()\n",
    "        self.act_fn = torch.nn.LeakyReLU(inplace=True) if act else torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.act_fn(self.nrm_fn(self.conv(x)))\n",
    "```\n",
    "\n",
    "However, we want a model that can be conditioned on time $t$, we use a shift-scale operation on the output of a normal convolution layer. \n",
    "\n",
    "```python\n",
    "class TimeConvBlock(ConvBlock):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        t_scale, t_shift = t.chunk(2, dim=1)\n",
    "        x = self.nrm_fn(self.conv(x))\n",
    "        return self.act_fn(x * (1 + t_scale[..., None, None]) + t_shift[..., None, None])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff858e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:05:03.459235Z",
     "iopub.status.busy": "2025-05-12T23:05:03.458927Z",
     "iopub.status.idle": "2025-05-12T23:05:03.469568Z",
     "shell.execute_reply": "2025-05-12T23:05:03.468228Z",
     "shell.execute_reply.started": "2025-05-12T23:05:03.459209Z"
    },
    "papermill": {
     "duration": 0.005574,
     "end_time": "2025-05-13T17:31:19.886233",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.880659",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These `TimeConvBlocks` will be combined to make a `TimeResidualBlock`.\n",
    "\n",
    "```python\n",
    "class TimeResidualBlock(torch.nn.Module):\n",
    "    \"\"\"Basic residual block with time conditioning.\n",
    "    Time conditioning is done by employing a scale/shift operator on the projected features before the activation.\n",
    "    Contains 3 convolutional blocks, the last one without activation.\n",
    "    The residual connection is added to the last output.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = TimeConvBlock(in_channels=channels, out_channels=channels)\n",
    "        self.conv_block_2 = TimeConvBlock(in_channels=channels, out_channels=channels)\n",
    "        self.conv_block_3 = TimeConvBlock(in_channels=channels, out_channels=channels, act=False)\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        r = x.clone()\n",
    "        x = self.conv_block_1(x=x,t=t)\n",
    "        x = self.conv_block_2(x=x,t=t)\n",
    "        return self.conv_block_3(x=x,t=t) + x\n",
    "```\n",
    "\n",
    "Both an an EncoderBlock and a DecoderBlock consist out of one `TimeResidualBlock` and a `Resample Block`. In the `EncoderBlock` the resample operation is done first, while in the `DecoderBlock` the resample operation is done last, such that the `TimeResidualBlock` operates on features maps of low resolution. \n",
    "\n",
    "```python\n",
    "class ResidualUnetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, upsample: bool, time_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        if self.upsample:\n",
    "            #This means it is an decoder block, so we do the first the convolution block, then the resample block\n",
    "            self.residual_block = TimeResidualBlock(channels=in_channels)\n",
    "            self.resample_block = ConvUpsample(in_channels=in_channels, out_channels=out_channels)\n",
    "        else:\n",
    "            #This means that it is an encoder block so first resample, then convolutional block\n",
    "            self.resample_block = ConvDownSample(in_channels=in_channels, out_channels=out_channels)\n",
    "            self.residual_block = TimeResidualBlock(channels=out_channels)\n",
    "        self.timestep_block = torch.nn.Sequential(\n",
    "                torch.nn.Linear(time_channels, out_channels*2 if not upsample else in_channels*2),\n",
    "                torch.nn.SiLU(),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        h = x.clone()\n",
    "        t = self.timestep_block(t)\n",
    "        if not self.upsample:\n",
    "            x = self.resample_block(x)\n",
    "        x = self.residual_block(x=x, t=t)\n",
    "        if self.upsample:\n",
    "            x = self.resample_block(x)        \n",
    "        return x, h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709e5ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-12T23:05:03.459235Z",
     "iopub.status.busy": "2025-05-12T23:05:03.458927Z",
     "iopub.status.idle": "2025-05-12T23:05:03.469568Z",
     "shell.execute_reply": "2025-05-12T23:05:03.468228Z",
     "shell.execute_reply.started": "2025-05-12T23:05:03.459209Z"
    },
    "papermill": {
     "duration": 0.005491,
     "end_time": "2025-05-13T17:31:19.897633",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.892142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Combining these blocks gives our model\n",
    "\n",
    "\n",
    "```python\n",
    "class UNET(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int, channels: list[int]) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.init_cnv = ConvBlock(in_channels=in_channels, out_channels=channels[0])\n",
    "        time_channels = channels[0] * 4\n",
    "        self.time_enc = torch.nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_channels=channels[0]*4),\n",
    "            torch.nn.Linear(channels[0]*4, channels[0]*4),\n",
    "            torch.nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        #Encoder/decoder\n",
    "        self.encoder = torch.nn.ModuleList([])\n",
    "        self.decoder = torch.nn.ModuleList([])\n",
    "        for in_channels, out_channels in zip(channels[:-1], channels[1:]):\n",
    "            self.encoder.append(ResidualUnetBlock(in_channels, out_channels, time_channels=time_channels, upsample=False))\n",
    "            self.decoder.append(ResidualUnetBlock(out_channels*2, in_channels,time_channels=time_channels,  upsample=True))\n",
    "        \n",
    "        self.attn_block = Attention2D(in_channels=channels[-1], out_channels=channels[-1]*2, head_channels=16, n_heads=4)\n",
    "        self.attn_norm = torch.nn.GroupNorm(num_groups=1, num_channels=channels[-1]*2)\n",
    "        self.final_cnv = ConvBlock(in_channels=channels[0]*2, out_channels=self.in_channels, nrm=False, act=False, )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.init_cnv(x)\n",
    "        t = self.time_enc(t)\n",
    "\n",
    "        skip_connection = []\n",
    "        for layer in self.encoder:\n",
    "            x, h = layer(x=x, t=t)\n",
    "            skip_connection.append(h)\n",
    "        x = self.attn_block(x)\n",
    "        x = self.attn_norm(x)\n",
    "        \n",
    "        for layer in self.decoder[::-1]:\n",
    "            x, _ = layer(x=x, t=t)\n",
    "            x = torch.cat((x, skip_connection.pop(-1)), dim=1)\n",
    "            \n",
    "        return self.final_cnv(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8b281e2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:19.911297Z",
     "iopub.status.busy": "2025-05-13T17:31:19.910936Z",
     "iopub.status.idle": "2025-05-13T17:31:31.217237Z",
     "shell.execute_reply": "2025-05-13T17:31:31.216276Z"
    },
    "papermill": {
     "duration": 11.315198,
     "end_time": "2025-05-13T17:31:31.219038",
     "exception": false,
     "start_time": "2025-05-13T17:31:19.903840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import einops\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d98f9e9",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:31.232696Z",
     "iopub.status.busy": "2025-05-13T17:31:31.232240Z",
     "iopub.status.idle": "2025-05-13T17:31:31.237162Z",
     "shell.execute_reply": "2025-05-13T17:31:31.236327Z"
    },
    "papermill": {
     "duration": 0.013532,
     "end_time": "2025-05-13T17:31:31.238848",
     "exception": false,
     "start_time": "2025-05-13T17:31:31.225316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "eval_steps = 100\n",
    "learning_rate = 0.0001\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.015\n",
    "diffusion_timesteps = 1000\n",
    "n_trn_steps = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "263eb7c1",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:31.252122Z",
     "iopub.status.busy": "2025-05-13T17:31:31.251813Z",
     "iopub.status.idle": "2025-05-13T17:31:33.125626Z",
     "shell.execute_reply": "2025-05-13T17:31:33.124776Z"
    },
    "papermill": {
     "duration": 1.882623,
     "end_time": "2025-05-13T17:31:33.127368",
     "exception": false,
     "start_time": "2025-05-13T17:31:31.244745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 55.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.64MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.78MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.0,), (1.0,))])\n",
    "dataset = torchvision.datasets.MNIST(root=\".\", transform=transforms, train=True, download=True)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323d9b0f",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.143666Z",
     "iopub.status.busy": "2025-05-13T17:31:33.142929Z",
     "iopub.status.idle": "2025-05-13T17:31:33.149596Z",
     "shell.execute_reply": "2025-05-13T17:31:33.148808Z"
    },
    "papermill": {
     "duration": 0.016187,
     "end_time": "2025-05-13T17:31:33.150929",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.134742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_diffusion_dict_np(\n",
    "    beta_start: float, beta_end: float, diffusion_timesteps: int\n",
    ") -> dict[str, np.ndarray]:\n",
    "    betas = np.linspace(beta_start, beta_end, diffusion_timesteps)\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "    alphas_cumprod_prev = np.pad(alphas_cumprod[:-1], (1, 0), constant_values=1.0)\n",
    "    sqrt_recip_alphas = np.sqrt(1.0 / alphas)\n",
    "    sqrt_alphas_cumprod = np.sqrt(alphas_cumprod)\n",
    "    sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - alphas_cumprod)\n",
    "    posterior_variance = betas * (1.0 - alphas_cumprod_prev) / (1.0 - alphas_cumprod)\n",
    "    return {\n",
    "        \"betas\": betas,\n",
    "        \"alphas\": alphas,\n",
    "        \"alphas_cumprod\": alphas_cumprod,\n",
    "        \"alphas_cumprod_prev\": alphas_cumprod_prev,\n",
    "        \"sqrt_recip_alphas\": sqrt_recip_alphas,\n",
    "        \"sqrt_alphas_cumprod\": sqrt_alphas_cumprod,\n",
    "        \"sqrt_one_minus_alphas_cumprod\": sqrt_one_minus_alphas_cumprod,\n",
    "        \"posterior_variance\": posterior_variance,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a37d0b40",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.166391Z",
     "iopub.status.busy": "2025-05-13T17:31:33.165912Z",
     "iopub.status.idle": "2025-05-13T17:31:33.172584Z",
     "shell.execute_reply": "2025-05-13T17:31:33.171724Z"
    },
    "papermill": {
     "duration": 0.015984,
     "end_time": "2025-05-13T17:31:33.173978",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.157994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def q_sample(\n",
    "    gaussian_dict_np: dict[str, np.ndarray],\n",
    "    x_start: np.ndarray,\n",
    "    timesteps: np.ndarray,\n",
    "    noise: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Forward process, this we add noise to x_start=x0.\n",
    "    The amount of noise we add is defined by the variance schedule defined.\n",
    "\n",
    "    Args:\n",
    "        x_start (torch.Tensor): Start \n",
    "        t (int): Diffusion timestep, this value determines the scale of the noise we will add.\n",
    "        noise (torch.Tensor, optional): The noise to add, this is the amount of noise the network should predict.\n",
    "    Returns:\n",
    "        torch.Tensor: x_t\n",
    "    \"\"\"\n",
    "\n",
    "    sqrt_alphas_cumprod_t = gaussian_dict_np[\"sqrt_alphas_cumprod\"][timesteps]\n",
    "    sqrt_one_minus_alphas_cumprod_t = gaussian_dict_np[\"sqrt_one_minus_alphas_cumprod\"][\n",
    "        timesteps\n",
    "    ]\n",
    "\n",
    "    return sqrt_alphas_cumprod_t.reshape(-1, 1, 1, 1) * x_start + sqrt_one_minus_alphas_cumprod_t.reshape(-1, 1, 1, 1) * noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c86cf1bd",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.191200Z",
     "iopub.status.busy": "2025-05-13T17:31:33.190902Z",
     "iopub.status.idle": "2025-05-13T17:31:33.198094Z",
     "shell.execute_reply": "2025-05-13T17:31:33.197329Z"
    },
    "papermill": {
     "duration": 0.017059,
     "end_time": "2025-05-13T17:31:33.199797",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.182738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels: int, \n",
    "                 out_channels: int, \n",
    "                 kernel_size: int = 3, \n",
    "                 stride: int = 1, \n",
    "                 padding: int = 1,\n",
    "                 bias: bool = False,\n",
    "                 nrm: bool = True,\n",
    "                 act: bool = True,\n",
    "                ) -> None:\n",
    "        \"\"\"A basic convolutional block, convolution, activation and normalization. Uses Groupnorm.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=kernel_size, \n",
    "            stride=stride, \n",
    "            padding=padding, \n",
    "            bias=bias)\n",
    "        \n",
    "        self.nrm_fn = torch.nn.GroupNorm(num_groups=8, num_channels=out_channels) if nrm else torch.nn.Identity()\n",
    "        self.act_fn = torch.nn.LeakyReLU(inplace=True) if act else torch.nn.Identity()\n",
    "\n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        return self.act_fn(self.nrm_fn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "128078e7",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.215900Z",
     "iopub.status.busy": "2025-05-13T17:31:33.215584Z",
     "iopub.status.idle": "2025-05-13T17:31:33.220868Z",
     "shell.execute_reply": "2025-05-13T17:31:33.220180Z"
    },
    "papermill": {
     "duration": 0.015359,
     "end_time": "2025-05-13T17:31:33.222346",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.206987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeConvBlock(ConvBlock):\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        t_scale, t_shift = t.chunk(2, dim=1)\n",
    "        x = self.nrm_fn(self.conv(x))\n",
    "        return self.act_fn(x * (1 + t_scale[..., None, None]) + t_shift[..., None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6c4993",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.237663Z",
     "iopub.status.busy": "2025-05-13T17:31:33.237319Z",
     "iopub.status.idle": "2025-05-13T17:31:33.243416Z",
     "shell.execute_reply": "2025-05-13T17:31:33.242329Z"
    },
    "papermill": {
     "duration": 0.015467,
     "end_time": "2025-05-13T17:31:33.244970",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.229503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvDownSample(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=2, padding=1, )\n",
    "        self.nrm_fn = torch.nn.GroupNorm(num_groups=8, num_channels=out_channels)\n",
    "        self.act_fn = torch.nn.LeakyReLU(inplace=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.act_fn(self.nrm_fn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6c0ede",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.260772Z",
     "iopub.status.busy": "2025-05-13T17:31:33.260228Z",
     "iopub.status.idle": "2025-05-13T17:31:33.267113Z",
     "shell.execute_reply": "2025-05-13T17:31:33.266114Z"
    },
    "papermill": {
     "duration": 0.016517,
     "end_time": "2025-05-13T17:31:33.268712",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.252195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvUpsample(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels:int, ) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1, )\n",
    "        self.nrm_fn = torch.nn.GroupNorm(num_groups=8, num_channels=out_channels)\n",
    "        self.act_fn = torch.nn.LeakyReLU(inplace=True)\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = torch.nn.functional.interpolate(x, scale_factor=2, )\n",
    "        return self.act_fn(self.nrm_fn(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d40fafc",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.283981Z",
     "iopub.status.busy": "2025-05-13T17:31:33.283696Z",
     "iopub.status.idle": "2025-05-13T17:31:33.290104Z",
     "shell.execute_reply": "2025-05-13T17:31:33.289238Z"
    },
    "papermill": {
     "duration": 0.016095,
     "end_time": "2025-05-13T17:31:33.291856",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.275761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TimeResidualBlock(torch.nn.Module):\n",
    "    \"\"\"Basic residual block with time conditioning.\n",
    "    Time conditioning is done by employing a scale/shift operator on the projected features before the activation.\n",
    "    Contains 3 convolutional blocks, the last one without activation.\n",
    "    The residual connection is added to the last output.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = TimeConvBlock(in_channels=channels, out_channels=channels)\n",
    "        self.conv_block_2 = TimeConvBlock(in_channels=channels, out_channels=channels)\n",
    "        self.conv_block_3 = TimeConvBlock(in_channels=channels, out_channels=channels, act=False)\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        r = x.clone()\n",
    "        x = self.conv_block_1(x=x,t=t)\n",
    "        x = self.conv_block_2(x=x,t=t)\n",
    "        return self.conv_block_3(x=x,t=t) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e49e7244",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.307293Z",
     "iopub.status.busy": "2025-05-13T17:31:33.306943Z",
     "iopub.status.idle": "2025-05-13T17:31:33.314208Z",
     "shell.execute_reply": "2025-05-13T17:31:33.313447Z"
    },
    "papermill": {
     "duration": 0.016816,
     "end_time": "2025-05-13T17:31:33.315849",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.299033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualUnetBlock(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, upsample: bool, time_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.upsample = upsample\n",
    "        if self.upsample:\n",
    "            #This means it is an decoder block, so we do the first the convolution block, then the resample block\n",
    "            self.residual_block = TimeResidualBlock(channels=in_channels)\n",
    "            self.resample_block = ConvUpsample(in_channels=in_channels, out_channels=out_channels)\n",
    "        else:\n",
    "            #This means that it is an encoder block so first resample, then convolutional block\n",
    "            self.resample_block = ConvDownSample(in_channels=in_channels, out_channels=out_channels)\n",
    "            self.residual_block = TimeResidualBlock(channels=out_channels)\n",
    "        self.timestep_block = torch.nn.Sequential(\n",
    "                torch.nn.Linear(time_channels, out_channels*2 if not upsample else in_channels*2),\n",
    "                torch.nn.SiLU(),\n",
    "            )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        h = x.clone()\n",
    "        t = self.timestep_block(t)\n",
    "        if not self.upsample:\n",
    "            x = self.resample_block(x)\n",
    "        x = self.residual_block(x=x, t=t)\n",
    "        if self.upsample:\n",
    "            x = self.resample_block(x)        \n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb9007bf",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.331637Z",
     "iopub.status.busy": "2025-05-13T17:31:33.331293Z",
     "iopub.status.idle": "2025-05-13T17:31:33.341226Z",
     "shell.execute_reply": "2025-05-13T17:31:33.340033Z"
    },
    "papermill": {
     "duration": 0.019905,
     "end_time": "2025-05-13T17:31:33.342847",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.322942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention2D(torch.nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, head_channels: int, n_heads: int, ) -> None:\n",
    "        \"\"\"Attention block that computes the self attention for each feature.\n",
    "        \n",
    "        First projects the features to Q, K, V embeddings.\n",
    "        Reshapes these blocks by collapsing the H, W axis.\n",
    "        Then computes a similarity score.\n",
    "        Then computes the output values.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_dim = head_channels * n_heads\n",
    "        self.q_scale = head_channels ** -0.5\n",
    "        self.n_heads = n_heads\n",
    "        self.out_channels = out_channels\n",
    "        self.conv_q = torch.nn.Conv2d(in_channels=in_channels, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv_k = torch.nn.Conv2d(in_channels=in_channels, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.conv_v = torch.nn.Conv2d(in_channels=in_channels, out_channels=self.embedding_dim, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "        self.conv_out = torch.nn.Conv2d(in_channels=self.embedding_dim, out_channels=self.out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        N, C, H, W = x.shape\n",
    "        q = self.conv_q(x)\n",
    "        k = self.conv_k(x)\n",
    "        v = self.conv_v(x)\n",
    "\n",
    "        # re-arrange the q, k, v from (N, C, H, W) to (N, n_heads, head_channels, HxW)\n",
    "        q = einops.rearrange(q, pattern=\"N (a b) H W -> N a b (H W)\", a=self.n_heads) * self.q_scale\n",
    "        k = einops.rearrange(k, pattern=\"N (a b) H W -> N a b (H W)\", a=self.n_heads)\n",
    "        v = einops.rearrange(v, pattern=\"N (a b) H W -> N a b (H W)\", a=self.n_heads)\n",
    "\n",
    "        similarity_matrix = torch.einsum(\"N a b i, N a b j -> N a i j\", q, k)\n",
    "        similarity_matrix = torch.nn.functional.softmax(similarity_matrix, dim=1)\n",
    "\n",
    "        output = torch.einsum(\"N a i j, N a d j -> N a i d\", similarity_matrix, v)\n",
    "        output = einops.rearrange(output, \"N a (H W) d->N (a d) H W\",  H=H, W=W)\n",
    "        return self.conv_out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1190a7d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.358022Z",
     "iopub.status.busy": "2025-05-13T17:31:33.357741Z",
     "iopub.status.idle": "2025-05-13T17:31:33.363896Z",
     "shell.execute_reply": "2025-05-13T17:31:33.363020Z"
    },
    "papermill": {
     "duration": 0.015423,
     "end_time": "2025-05-13T17:31:33.365280",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.349857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(torch.nn.Module):\n",
    "    def __init__(self, time_channels: int) -> None:\n",
    "        super().__init__()\n",
    "        self.time_channels = time_channels\n",
    "        self.embeddings = torch.log(torch.Tensor([10_000])) / (self.time_channels // 2 - 1)\n",
    "\n",
    "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
    "        embeddings = torch.exp(torch.arange(self.time_channels // 2, device=t.device) * -self.embeddings.to(t.device))\n",
    "        embeddings = t[:, None] * embeddings[None, :]\n",
    "        return torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6386677b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.381571Z",
     "iopub.status.busy": "2025-05-13T17:31:33.380854Z",
     "iopub.status.idle": "2025-05-13T17:31:33.390816Z",
     "shell.execute_reply": "2025-05-13T17:31:33.389951Z"
    },
    "papermill": {
     "duration": 0.019247,
     "end_time": "2025-05-13T17:31:33.392098",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.372851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UNET(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels: int, channels: list[int]) -> None:\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.channels = channels\n",
    "        self.init_cnv = ConvBlock(in_channels=in_channels, out_channels=channels[0])\n",
    "        time_channels = channels[0] * 4\n",
    "        self.time_enc = torch.nn.Sequential(\n",
    "            SinusoidalPositionEmbeddings(time_channels=channels[0]*4),\n",
    "            torch.nn.Linear(channels[0]*4, channels[0]*4),\n",
    "            torch.nn.SiLU(),\n",
    "        )\n",
    "\n",
    "        #Encoder/decoder\n",
    "        self.encoder = torch.nn.ModuleList([])\n",
    "        self.decoder = torch.nn.ModuleList([])\n",
    "        for in_channels, out_channels in zip(channels[:-1], channels[1:]):\n",
    "            self.encoder.append(ResidualUnetBlock(in_channels, out_channels, time_channels=time_channels, upsample=False))\n",
    "            self.decoder.append(ResidualUnetBlock(out_channels*2, in_channels,time_channels=time_channels,  upsample=True))\n",
    "        \n",
    "        self.attn_block = Attention2D(in_channels=channels[-1], out_channels=channels[-1]*2, head_channels=16, n_heads=4)\n",
    "        self.attn_norm = torch.nn.GroupNorm(num_groups=1, num_channels=channels[-1]*2)\n",
    "        self.final_cnv = ConvBlock(in_channels=channels[0]*2, out_channels=self.in_channels, nrm=False, act=False, )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.init_cnv(x)\n",
    "        t = self.time_enc(t)\n",
    "\n",
    "        skip_connection = []\n",
    "        for layer in self.encoder:\n",
    "            x, h = layer(x=x, t=t)\n",
    "            skip_connection.append(h)\n",
    "        x = self.attn_block(x)\n",
    "        x = self.attn_norm(x)\n",
    "        \n",
    "        for layer in self.decoder[::-1]:\n",
    "            x, _ = layer(x=x, t=t)\n",
    "            x = torch.cat((x, skip_connection.pop(-1)), dim=1)\n",
    "            \n",
    "        return self.final_cnv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eee7909c",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.407725Z",
     "iopub.status.busy": "2025-05-13T17:31:33.407422Z",
     "iopub.status.idle": "2025-05-13T17:31:33.413053Z",
     "shell.execute_reply": "2025-05-13T17:31:33.411988Z"
    },
    "papermill": {
     "duration": 0.015234,
     "end_time": "2025-05-13T17:31:33.414621",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.399387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def batch_distort(x_trn: torch.Tensor, batch_size: int, t: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    if t == None:\n",
    "        t = torch.randint(0, diffusion_timesteps-1, (batch_size,))\n",
    "    noise = torch.randn_like(x_trn)\n",
    "    xt = q_sample(gaussian_dict_np=diffusion_dict_np, x_start = x_trn.numpy(), timesteps=t.numpy(), noise=noise.numpy())\n",
    "    return torch.from_numpy(xt).to(torch.float32), noise, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92f36718",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.430139Z",
     "iopub.status.busy": "2025-05-13T17:31:33.429830Z",
     "iopub.status.idle": "2025-05-13T17:31:33.435533Z",
     "shell.execute_reply": "2025-05-13T17:31:33.434617Z"
    },
    "papermill": {
     "duration": 0.015202,
     "end_time": "2025-05-13T17:31:33.436991",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.421789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_q_sample(x: torch.Tensor, xt: torch.Tensor, ) -> None:\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].imshow(xt, cmap=\"binary\")\n",
    "    axs[1].imshow(x, cmap=\"binary\")\n",
    "    axs[0].set_title(r\"$x_t$\")\n",
    "    axs[1].set_title(r\"$x_0$\")\n",
    "    _ = [ax.axis(\"off\") for ax in axs.flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053647a1",
   "metadata": {
    "papermill": {
     "duration": 0.006686,
     "end_time": "2025-05-13T17:31:33.450761",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.444075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - From definition to loss function </b></div>\n",
    "\n",
    "Okey, now we have everything defined we can finally train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efae087f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.466093Z",
     "iopub.status.busy": "2025-05-13T17:31:33.465798Z",
     "iopub.status.idle": "2025-05-13T17:31:33.527961Z",
     "shell.execute_reply": "2025-05-13T17:31:33.526982Z"
    },
    "papermill": {
     "duration": 0.071934,
     "end_time": "2025-05-13T17:31:33.529686",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.457752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unet = UNET(in_channels=1, channels=[16, 32, 64])\n",
    "optimizer = torch.optim.Adam(params=unet.parameters(), lr=learning_rate, )\n",
    "diffusion_dict_np = get_diffusion_dict_np(beta_start=beta_start, beta_end=beta_end, diffusion_timesteps=diffusion_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3077731",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T17:31:33.544897Z",
     "iopub.status.busy": "2025-05-13T17:31:33.544588Z",
     "iopub.status.idle": "2025-05-13T18:04:38.439442Z",
     "shell.execute_reply": "2025-05-13T18:04:38.438369Z"
    },
    "papermill": {
     "duration": 1984.905167,
     "end_time": "2025-05-13T18:04:38.441727",
     "exception": false,
     "start_time": "2025-05-13T17:31:33.536560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5000 loss: 1.1611\n",
      "100/5000 loss: 0.4566\n",
      "200/5000 loss: 0.2470\n",
      "300/5000 loss: 0.1540\n",
      "400/5000 loss: 0.1307\n",
      "500/5000 loss: 0.1065\n",
      "600/5000 loss: 0.1035\n",
      "700/5000 loss: 0.0730\n",
      "800/5000 loss: 0.0828\n",
      "900/5000 loss: 0.1051\n",
      "1000/5000 loss: 0.0496\n",
      "1100/5000 loss: 0.0504\n",
      "1200/5000 loss: 0.0453\n",
      "1300/5000 loss: 0.0640\n",
      "1400/5000 loss: 0.0455\n",
      "1500/5000 loss: 0.0474\n",
      "1600/5000 loss: 0.0513\n",
      "1700/5000 loss: 0.0360\n",
      "1800/5000 loss: 0.0379\n",
      "1900/5000 loss: 0.0515\n",
      "2000/5000 loss: 0.0441\n",
      "2100/5000 loss: 0.0436\n",
      "2200/5000 loss: 0.0702\n",
      "2300/5000 loss: 0.0316\n",
      "2400/5000 loss: 0.0425\n",
      "2500/5000 loss: 0.0378\n",
      "2600/5000 loss: 0.0220\n",
      "2700/5000 loss: 0.0442\n",
      "2800/5000 loss: 0.0522\n",
      "2900/5000 loss: 0.0489\n",
      "3000/5000 loss: 0.0373\n",
      "3100/5000 loss: 0.0338\n",
      "3200/5000 loss: 0.0347\n",
      "3300/5000 loss: 0.0570\n",
      "3400/5000 loss: 0.0460\n",
      "3500/5000 loss: 0.0370\n",
      "3600/5000 loss: 0.0343\n",
      "3700/5000 loss: 0.0384\n",
      "3800/5000 loss: 0.0429\n",
      "3900/5000 loss: 0.0370\n",
      "4000/5000 loss: 0.0414\n",
      "4100/5000 loss: 0.0315\n",
      "4200/5000 loss: 0.0330\n",
      "4300/5000 loss: 0.0434\n",
      "4400/5000 loss: 0.0420\n",
      "4500/5000 loss: 0.0298\n",
      "4600/5000 loss: 0.0402\n",
      "4700/5000 loss: 0.0457\n",
      "4800/5000 loss: 0.0421\n",
      "4900/5000 loss: 0.0294\n"
     ]
    }
   ],
   "source": [
    "iter_loader = iter(loader)\n",
    "for step in range(n_trn_steps):\n",
    "    try: \n",
    "        x_trn, _ = next(iter_loader)\n",
    "    except StopIteration:\n",
    "        iter_loader = iter(loader)\n",
    "        x_trn, _ = next(iter_loader)\n",
    "    xt, noise, t = batch_distort(x_trn=x_trn, batch_size=batch_size, t=None)\n",
    "    predicted_noise = unet(x=xt, t=t)\n",
    "    loss = torch.nn.functional.mse_loss(predicted_noise, noise)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % eval_steps == 0:\n",
    "        print(f\"{step}/{n_trn_steps} loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8d515",
   "metadata": {
    "papermill": {
     "duration": 0.009078,
     "end_time": "2025-05-13T18:04:38.460399",
     "exception": false,
     "start_time": "2025-05-13T18:04:38.451321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - Sampling steps </b></div>\n",
    "\n",
    "Okey, now we have our model, we can sample some digits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6841c94e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T18:04:38.481032Z",
     "iopub.status.busy": "2025-05-13T18:04:38.480372Z",
     "iopub.status.idle": "2025-05-13T18:06:51.440329Z",
     "shell.execute_reply": "2025-05-13T18:06:51.438694Z"
    },
    "papermill": {
     "duration": 132.97226,
     "end_time": "2025-05-13T18:06:51.442067",
     "exception": false,
     "start_time": "2025-05-13T18:04:38.469807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:12,  7.51it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    xt = torch.randn_like(xt)\n",
    "    for timestep in tqdm(reversed(range(0, diffusion_timesteps-1))):\n",
    "        t = torch.ones_like(xt[:, 0, 0, 0]) * timestep\n",
    "        et = unet(x=xt, t=t)\n",
    "        model_mean = diffusion_dict_np[\"sqrt_recip_alphas\"][timestep] * (xt - diffusion_dict_np[\"betas\"][timestep] * et.detach().numpy() /diffusion_dict_np[\"sqrt_one_minus_alphas_cumprod\"][timestep])\n",
    "        if timestep != 0:\n",
    "            xt = model_mean + np.sqrt(\n",
    "                    diffusion_dict_np[\"posterior_variance\"][timestep]\n",
    "                ) * torch.randn_like(model_mean)\n",
    "        else:\n",
    "            xt = model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e648d84b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-13T18:06:51.558139Z",
     "iopub.status.busy": "2025-05-13T18:06:51.557813Z",
     "iopub.status.idle": "2025-05-13T18:06:51.820536Z",
     "shell.execute_reply": "2025-05-13T18:06:51.819533Z"
    },
    "papermill": {
     "duration": 0.321826,
     "end_time": "2025-05-13T18:06:51.822192",
     "exception": false,
     "start_time": "2025-05-13T18:06:51.500366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7e3760701a90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xt[10, 0].numpy(), cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30fdec8",
   "metadata": {
    "papermill": {
     "duration": 0.054049,
     "end_time": "2025-05-13T18:06:51.931182",
     "exception": false,
     "start_time": "2025-05-13T18:06:51.877133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#1279D4; overflow:hidden\"><b> Diffusion models - Sources </b></div>\n",
    "\n",
    "\n",
    "This amazing blogpost helped me understand (most of) the math behind diffusion models and inspired me to make my own blogpost combining both the math and python code.\n",
    "```bib\n",
    "@article{weng2021diffusion,\n",
    "  title   = \"What are diffusion models?\",\n",
    "  author  = \"Weng, Lilian\",\n",
    "  journal = \"lilianweng.github.io\",\n",
    "  year    = \"2021\",\n",
    "  month   = \"Jul\",\n",
    "  url     = \"https://lilianweng.github.io/posts/2021-07-11-diffusion-models/\"\n",
    "}\n",
    "\n",
    "```\n",
    "This blogpost explained the reparameterization trick.\n",
    "```bib\n",
    "@article{weng2018VAE,\n",
    "  title   = \"From Autoencoder to Beta-VAE\",\n",
    "  author  = \"Weng, Lilian\",\n",
    "  journal = \"lilianweng.github.io\",\n",
    "  year    = \"2018\",\n",
    "  url     = \"https://lilianweng.github.io/posts/2018-08-12-vae/\"\n",
    "}\n",
    "```\n",
    "\n",
    "This work and the [blogpost](https://yang-song.net/blog/2021/score/) inspired most of the schematics\n",
    "```bib\n",
    "@inproceedings{\n",
    "  song2021scorebased,\n",
    "  title={Score-Based Generative Modeling through Stochastic Differential Equations},\n",
    "  author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole},\n",
    "  booktitle={International Conference on Learning Representations},\n",
    "  year={2021},\n",
    "  url={https://openreview.net/forum?id=PxTIG12RRHS}\n",
    "}\n",
    "```\n",
    "\n",
    "The pytorch code I wrote for this blog was written from scratch to help me explain the algorithm, but it was inspired by the [code](https://github.com/openai/improved-diffusion/tree/main) from this work\n",
    "```bib\n",
    "@article{DBLP:journals/corr/abs-2102-09672,\n",
    "  author       = {Alex Nichol and\n",
    "                  Prafulla Dhariwal},\n",
    "  title        = {Improved Denoising Diffusion Probabilistic Models},\n",
    "  journal      = {CoRR},\n",
    "  volume       = {abs/2102.09672},\n",
    "  year         = {2021},\n",
    "  url          = {https://arxiv.org/abs/2102.09672},\n",
    "  eprinttype    = {arXiv},\n",
    "  eprint       = {2102.09672},\n",
    "  timestamp    = {Wed, 24 Feb 2021 15:42:45 +0100},\n",
    "  biburl       = {https://dblp.org/rec/journals/corr/abs-2102-09672.bib},\n",
    "  bibsource    = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "And ofcourse, to the work on diffusion models;\n",
    "\n",
    "```bib\n",
    "@article{DBLP:journals/corr/abs-2006-11239,\n",
    "  author       = {Jonathan Ho and\n",
    "                  Ajay Jain and\n",
    "                  Pieter Abbeel},\n",
    "  title        = {Denoising Diffusion Probabilistic Models},\n",
    "  journal      = {CoRR},\n",
    "  volume       = {abs/2006.11239},\n",
    "  year         = {2020},\n",
    "  url          = {https://arxiv.org/abs/2006.11239},\n",
    "  eprinttype    = {arXiv},\n",
    "  eprint       = {2006.11239},\n",
    "  timestamp    = {Tue, 23 Jun 2020 17:57:22 +0200},\n",
    "  biburl       = {https://dblp.org/rec/journals/corr/abs-2006-11239.bib},\n",
    "  bibsource    = {dblp computer science bibliography, https://dblp.org}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70dcb2",
   "metadata": {
    "papermill": {
     "duration": 0.054076,
     "end_time": "2025-05-13T18:06:52.039749",
     "exception": false,
     "start_time": "2025-05-13T18:06:51.985673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2140.87985,
   "end_time": "2025-05-13T18:06:55.264541",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-13T17:31:14.384691",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
